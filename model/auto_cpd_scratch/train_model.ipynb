{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "n_samples = 2000\n",
    "segment_length = 50"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_data(n_samples, seq_length):\n",
    "    # Class 0: n_samples sequences of length seq_length, mean 0, variance 1\n",
    "    x_class_0 = np.random.normal(loc=0, scale=0.5, size=(n_samples, seq_length))\n",
    "    y_class_0 = np.zeros(n_samples)\n",
    "\n",
    "    # Class 1: initialize list to hold individual sequences\n",
    "    x_class_1 = []\n",
    "    y_class_1 = np.ones(n_samples)\n",
    "\n",
    "    for _ in range(n_samples):\n",
    "        # Generate unique cp and ran_mean for each sample\n",
    "        cp = np.random.randint(int(seq_length * 0.25), int(seq_length * 0.75))\n",
    "        ran_mean = np.random.choice([-1, 1])\n",
    "\n",
    "        # Create a sequence with left segment mean 0 and right segment mean ran_mean\n",
    "        left_segment = np.random.normal(0, 0.5, (seq_length - cp))\n",
    "        right_segment = np.random.normal(ran_mean, 0.5, (cp))\n",
    "        x_class_1.append(np.hstack((left_segment, right_segment)))\n",
    "\n",
    "    # Convert list to numpy array\n",
    "    x_class_1 = np.array(x_class_1)\n",
    "\n",
    "    # Combine all data\n",
    "    X = np.vstack((x_class_0, x_class_1))\n",
    "    y = np.concatenate((y_class_0, y_class_1))\n",
    "\n",
    "    X_scaled = np.zeros_like(X)  # Initialize array for scaled data\n",
    "    for i in range(X.shape[0]):\n",
    "        scaler = MinMaxScaler(feature_range=(0, 1))\n",
    "        X_scaled[i, :] = scaler.fit_transform(X[i, :].reshape(-1, 1)).flatten()\n",
    "\n",
    "    return X_scaled, y\n",
    "\n",
    "# Generate the data\n",
    "X, y = generate_data(n_samples, segment_length)\n",
    "\n",
    "# Convert data to PyTorch tensors\n",
    "X_tensor = torch.tensor(X, dtype=torch.float32)\n",
    "y_tensor = torch.tensor(y, dtype=torch.float32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# for i in range(10):\n",
    "#     plt.scatter(np.arange(len(X[i])), X[i])\n",
    "#     plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Step 2: Define the MLP Model\n",
    "class MLPClassifier(nn.Module):\n",
    "    def __init__(self, intput_size):\n",
    "        super(MLPClassifier, self).__init__()\n",
    "        self.fc1 = nn.Linear(intput_size, 64)\n",
    "        self.fc2 = nn.Linear(64, 32)\n",
    "        self.fc3 = nn.Linear(32, 1)\n",
    "        self.relu = nn.ReLU()\n",
    "        self.sigmoid = nn.Sigmoid()\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.relu(self.fc1(x))\n",
    "        x = self.relu(self.fc2(x))\n",
    "        x = self.sigmoid(self.fc3(x))\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [0/10000], Loss: 0.69381559, Val Loss: 0.69339567, Training Accuracy: 48.69%, Validation Accuracy: 50.50%\n",
      "Epoch [100/10000], Loss: 0.17649092, Val Loss: 0.18114978, Training Accuracy: 97.97%, Validation Accuracy: 98.00%\n",
      "Epoch [200/10000], Loss: 0.03152816, Val Loss: 0.04753244, Training Accuracy: 99.53%, Validation Accuracy: 98.87%\n",
      "Epoch [300/10000], Loss: 0.01361094, Val Loss: 0.03740959, Training Accuracy: 99.97%, Validation Accuracy: 98.87%\n",
      "Epoch [400/10000], Loss: 0.00658713, Val Loss: 0.03405719, Training Accuracy: 100.00%, Validation Accuracy: 99.25%\n",
      "Epoch [500/10000], Loss: 0.00365460, Val Loss: 0.03377058, Training Accuracy: 100.00%, Validation Accuracy: 99.37%\n",
      "Early stopping triggered\n",
      "Training complete. Best model saved with validation loss: tensor(0.0337)\n"
     ]
    }
   ],
   "source": [
    "# Initialize the model, loss function, and optimizer\n",
    "model = MLPClassifier(segment_length)\n",
    "criterion = nn.BCELoss()  # Binary Cross-Entropy Loss for binary classification\n",
    "optimizer = optim.Adam(model.parameters(), lr=0.001)\n",
    "\n",
    "# Step 3: Train the Model\n",
    "# Split data into subtrain (80%) and validation (20%)\n",
    "X_subtrain, X_val, y_subtrain, y_val = train_test_split(X_tensor, y_tensor, test_size=0.2, random_state=42)\n",
    "\n",
    "# Early stopping criteria\n",
    "min_val_loss = float('inf')\n",
    "epochs_without_improvement = 0\n",
    "early_stop_patience = 100\n",
    "best_model_state = None\n",
    "\n",
    "# Training loop\n",
    "num_epochs = 10000\n",
    "for epoch in range(num_epochs):\n",
    "    # Set model to training mode\n",
    "    model.train()\n",
    "    \n",
    "    # Forward pass on subtrain data\n",
    "    optimizer.zero_grad()\n",
    "    outputs = model(X_subtrain).squeeze()\n",
    "    loss = criterion(outputs, y_subtrain)\n",
    "    \n",
    "    # Backward pass and optimization\n",
    "    loss.backward()\n",
    "    optimizer.step()\n",
    "\n",
    "    # Calculate accuracy on subtrain\n",
    "    with torch.no_grad():\n",
    "        train_preds = (outputs > 0.5).float()  # Binary prediction threshold at 0.5\n",
    "        train_accuracy = (train_preds == y_subtrain).float().mean().item() * 100\n",
    "\n",
    "    # Evaluate on validation set\n",
    "    model.eval()\n",
    "    with torch.no_grad():\n",
    "        val_outputs = model(X_val).squeeze()\n",
    "        val_loss = criterion(val_outputs, y_val)\n",
    "        \n",
    "        # Calculate accuracy on validation set\n",
    "        val_preds = (val_outputs > 0.5).float()\n",
    "        val_accuracy = (val_preds == y_val).float().mean().item() * 100\n",
    "\n",
    "    # Early stopping check\n",
    "    if val_loss < min_val_loss:\n",
    "        min_val_loss = val_loss\n",
    "        epochs_without_improvement = 0\n",
    "        best_model_state = model.state_dict()\n",
    "    else:\n",
    "        epochs_without_improvement += 1\n",
    "\n",
    "    # Print loss values and accuracies for tracking\n",
    "    if epoch % 100 == 0:\n",
    "        print(f\"Epoch [{epoch}/{num_epochs}], Loss: {loss.item():.8f}, Val Loss: {val_loss.item():.8f}, Training Accuracy: {train_accuracy:.2f}%, Validation Accuracy: {val_accuracy:.2f}%\")\n",
    "\n",
    "    # Stop training if no improvement for `early_stop_patience` epochs\n",
    "    if epochs_without_improvement >= early_stop_patience:\n",
    "        print(\"Early stopping triggered\")\n",
    "        break\n",
    "\n",
    "# Load the best model state based on validation loss\n",
    "model.load_state_dict(best_model_state)\n",
    "print(\"Training complete. Best model saved with validation loss:\", min_val_loss)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.save(model, 'trained_model.pth')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "scripted_model = torch.jit.script(model)\n",
    "scripted_model.save(\"trained_model.pth\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
